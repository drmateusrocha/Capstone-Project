{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da70ee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2112 entries, 0 to 2111\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         2112 non-null   int64  \n",
      " 1   Substrate  2112 non-null   object \n",
      " 2   Ceramic    2112 non-null   object \n",
      " 3   Thickness  2112 non-null   float64\n",
      " 4   Lsub       2112 non-null   float64\n",
      " 5   asub       2112 non-null   float64\n",
      " 6   bsub       2112 non-null   float64\n",
      " 7   Lcer       2112 non-null   float64\n",
      " 8   acer       2112 non-null   float64\n",
      " 9   bcer       2112 non-null   float64\n",
      " 10  L          2112 non-null   float64\n",
      " 11  a          2112 non-null   float64\n",
      " 12  b          2112 non-null   float64\n",
      "dtypes: float64(10), int64(1), object(2)\n",
      "memory usage: 214.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, TimeDistributed\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('../data/data2.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7bcc7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d5ac35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1478, 7)\n",
      "(1478, 3)\n",
      "(634, 7)\n",
      "(634, 3)\n"
     ]
    }
   ],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable=['L', 'a', 'b']\n",
    "Predictors=['Thickness','Lsub', 'asub','bsub', 'Lcer', 'acer', 'bcer']\n",
    " \n",
    "X=df[Predictors].values\n",
    "y=df[TargetVariable].values\n",
    " \n",
    "### Sandardization of data ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    " \n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    " \n",
    "# Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    " \n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    " \n",
    "# Quick sanity check with the shapes of Training and testing datasets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "32323e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b3bd04cd0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "# create ANN model\n",
    "model = Sequential()\n",
    " \n",
    "# Defining the Input layer and FIRST hidden layer, both are same!\n",
    "model.add(Dense(units=2, input_dim=7, kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "# Defining the Second layer of the model\n",
    "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
    "model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "# There are 3 output neurons since we will be predicting a single number\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    " \n",
    "# Compiling the model\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    " \n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train ,batch_size = 20, epochs = 50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "02747945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on training data: 0.27581822872161865\n",
      "model score on testing data: 0.2624717950820923\n"
     ]
    }
   ],
   "source": [
    "print(f'model score on training data: {model.evaluate(X_train, y_train, verbose = 0)}')\n",
    "print(f'model score on testing data: {model.evaluate(X_test, y_test, verbose = 0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "617efeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes):\n",
    "    layers = []\n",
    "    \n",
    "    nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "    nodes = first_layer_nodes\n",
    "    for i in range(1, n_layers+1):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b42eef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel(n_layers, first_layer_nodes, last_layer_nodes, activation_func, loss_func):\n",
    "    model = Sequential()\n",
    "    n_nodes = FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=activation_func))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            \n",
    "    #Finally, the output layer should have a single node in binary classification\n",
    "    model.add(Dense(3, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss=loss_func, metrics = [\"accuracy\"]) #note: metrics could also be 'mse'\n",
    "    \n",
    "    return model\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model =  KerasRegressor(build_fn=createmodel, verbose = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "943873ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_funcs = ['relu']#['sigmoid', 'relu', 'tanh'] \n",
    "loss_funcs = ['mae'] #['mean_squared_error','hinge','mae']\n",
    "param_grid = dict(n_layers=[1,2], first_layer_nodes = [20, 10, 5, 3], last_layer_nodes = [20, 10, 5, 3],  activation_func = activation_funcs, loss_func = loss_funcs, batch_size = [20, 50, 100], epochs = [20, 50, 100])\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv=10, n_jobs=-1, verbose=1, scoring = \"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "42510034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 288 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 13:52:36.459201: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.459202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.459201: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.459309: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.459341: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.459203: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.459205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.459923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.459985: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.460078: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.460644: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.459983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.461044: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.461044: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.461148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:36.462086: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654037: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654112: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654235: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654037: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654113: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654333: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654408: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654593: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654623: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.654678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.655212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 13:52:44.655410: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe568a35b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe6f801f700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ae8cb3700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe54879dee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe73895a430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b18925430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8287424c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8d08b8700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe468710280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8730b830d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0f87a0ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe828660280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe878842430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe3c8649670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fae38960430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc258b1c700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87e081b4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0b0c08700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4e878f550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc388485e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fadd8770310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa6e096eee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc1c87cf430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8228af4430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd56098d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4a86d3310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdbc87fddc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa658708ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e87ba940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb47074c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd588a86dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c86cd040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 1.85 s, total: 16.4 s\n",
      "Wall time: 10min 13s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7f7b7bdb4f10&gt;,\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation_func&#x27;: [&#x27;relu&#x27;],\n",
       "                         &#x27;batch_size&#x27;: [20, 50, 100], &#x27;epochs&#x27;: [20, 50, 100],\n",
       "                         &#x27;first_layer_nodes&#x27;: [20, 10, 5, 3],\n",
       "                         &#x27;last_layer_nodes&#x27;: [20, 10, 5, 3],\n",
       "                         &#x27;loss_func&#x27;: [&#x27;mae&#x27;], &#x27;n_layers&#x27;: [1, 2]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7f7b7bdb4f10&gt;,\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation_func&#x27;: [&#x27;relu&#x27;],\n",
       "                         &#x27;batch_size&#x27;: [20, 50, 100], &#x27;epochs&#x27;: [20, 50, 100],\n",
       "                         &#x27;first_layer_nodes&#x27;: [20, 10, 5, 3],\n",
       "                         &#x27;last_layer_nodes&#x27;: [20, 10, 5, 3],\n",
       "                         &#x27;loss_func&#x27;: [&#x27;mae&#x27;], &#x27;n_layers&#x27;: [1, 2]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7f7b7bdb4f10&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7f7b7bdb4f10&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f7b7bdb4f10>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation_func': ['relu'],\n",
       "                         'batch_size': [20, 50, 100], 'epochs': [20, 50, 100],\n",
       "                         'first_layer_nodes': [20, 10, 5, 3],\n",
       "                         'last_layer_nodes': [20, 10, 5, 3],\n",
       "                         'loss_func': ['mae'], 'n_layers': [1, 2]},\n",
       "             scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d627c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.772307140877106\n",
      "{'activation_func': 'relu', 'batch_size': 20, 'epochs': 100, 'first_layer_nodes': 20, 'last_layer_nodes': 5, 'loss_func': 'mae', 'n_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39ae18a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation_func</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_first_layer_nodes</th>\n",
       "      <th>param_last_layer_nodes</th>\n",
       "      <th>param_loss_func</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>21.575250</td>\n",
       "      <td>0.437942</td>\n",
       "      <td>0.353753</td>\n",
       "      <td>0.099120</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>mae</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.134190</td>\n",
       "      <td>-4.902070</td>\n",
       "      <td>-7.778824</td>\n",
       "      <td>-5.823147</td>\n",
       "      <td>-9.490871</td>\n",
       "      <td>-6.770509</td>\n",
       "      <td>-4.972310</td>\n",
       "      <td>-5.772307</td>\n",
       "      <td>1.695176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>21.555418</td>\n",
       "      <td>0.392655</td>\n",
       "      <td>0.410079</td>\n",
       "      <td>0.142938</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.934565</td>\n",
       "      <td>-5.991244</td>\n",
       "      <td>-7.815599</td>\n",
       "      <td>-6.078732</td>\n",
       "      <td>-5.980242</td>\n",
       "      <td>-7.233397</td>\n",
       "      <td>-13.910946</td>\n",
       "      <td>-7.461904</td>\n",
       "      <td>2.766230</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>21.200536</td>\n",
       "      <td>0.445029</td>\n",
       "      <td>0.393060</td>\n",
       "      <td>0.096721</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>mae</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.064161</td>\n",
       "      <td>-6.762966</td>\n",
       "      <td>-8.399285</td>\n",
       "      <td>-5.435592</td>\n",
       "      <td>-14.088329</td>\n",
       "      <td>-4.853755</td>\n",
       "      <td>-10.775963</td>\n",
       "      <td>-7.817438</td>\n",
       "      <td>2.756097</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>20.727092</td>\n",
       "      <td>0.465541</td>\n",
       "      <td>0.343512</td>\n",
       "      <td>0.087140</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>mae</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.957953</td>\n",
       "      <td>-8.214135</td>\n",
       "      <td>-9.641896</td>\n",
       "      <td>-9.683310</td>\n",
       "      <td>-10.802942</td>\n",
       "      <td>-9.133189</td>\n",
       "      <td>-13.920956</td>\n",
       "      <td>-8.438978</td>\n",
       "      <td>2.660604</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>8.981509</td>\n",
       "      <td>0.284565</td>\n",
       "      <td>0.332793</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.959008</td>\n",
       "      <td>-10.786463</td>\n",
       "      <td>-7.623669</td>\n",
       "      <td>-9.229834</td>\n",
       "      <td>-9.745437</td>\n",
       "      <td>-7.278907</td>\n",
       "      <td>-12.664578</td>\n",
       "      <td>-9.258146</td>\n",
       "      <td>2.787260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "69       21.575250      0.437942         0.353753        0.099120   \n",
       "71       21.555418      0.392655         0.410079        0.142938   \n",
       "67       21.200536      0.445029         0.393060        0.096721   \n",
       "65       20.727092      0.465541         0.343512        0.087140   \n",
       "167       8.981509      0.284565         0.332793        0.071534   \n",
       "\n",
       "    param_activation_func param_batch_size param_epochs  \\\n",
       "69                   relu               20          100   \n",
       "71                   relu               20          100   \n",
       "67                   relu               20          100   \n",
       "65                   relu               20          100   \n",
       "167                  relu               50          100   \n",
       "\n",
       "    param_first_layer_nodes param_last_layer_nodes param_loss_func  ...  \\\n",
       "69                       20                      5             mae  ...   \n",
       "71                       20                      3             mae  ...   \n",
       "67                       20                     10             mae  ...   \n",
       "65                       20                     20             mae  ...   \n",
       "167                      20                      3             mae  ...   \n",
       "\n",
       "    split3_test_score split4_test_score  split5_test_score  split6_test_score  \\\n",
       "69          -5.134190         -4.902070          -7.778824          -5.823147   \n",
       "71          -6.934565         -5.991244          -7.815599          -6.078732   \n",
       "67          -5.064161         -6.762966          -8.399285          -5.435592   \n",
       "65          -6.957953         -8.214135          -9.641896          -9.683310   \n",
       "167         -8.959008        -10.786463          -7.623669          -9.229834   \n",
       "\n",
       "     split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "69           -9.490871          -6.770509          -4.972310        -5.772307   \n",
       "71           -5.980242          -7.233397         -13.910946        -7.461904   \n",
       "67          -14.088329          -4.853755         -10.775963        -7.817438   \n",
       "65          -10.802942          -9.133189         -13.920956        -8.438978   \n",
       "167          -9.745437          -7.278907         -12.664578        -9.258146   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "69         1.695176                1  \n",
       "71         2.766230                2  \n",
       "67         2.756097                3  \n",
       "65         2.660604                4  \n",
       "167        2.787260                5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(grid.cv_results_)\n",
    "score_df.sort_values(by='rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "40ca5416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 698us/step\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train ,batch_size = 15, epochs = 5, verbose=0)\n",
    " \n",
    "# Generating Predictions on testing data\n",
    "Predictions=model.predict(X_test)\n",
    " \n",
    "# Scaling the predicted Price data back to original price scale\n",
    "Predictions=TargetVarScalerFit.inverse_transform(Predictions)\n",
    " \n",
    "# Scaling the y_test Price data back to original price scale\n",
    "y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    " \n",
    "# Scaling the test data back to original scale\n",
    "Test_Data=PredictorScalerFit.inverse_transform(X_test)\n",
    "\n",
    "TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n",
    "y_orig = pd.DataFrame(data=y_test_orig, columns=TargetVariable)\n",
    "y_pred = pd.DataFrame(data=Predictions, columns=TargetVariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c228d258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1.430\n",
      ">1.295\n",
      ">1.457\n",
      ">1.652\n",
      ">1.110\n",
      ">1.461\n",
      ">1.462\n",
      ">1.626\n",
      ">1.750\n",
      ">1.190\n",
      ">1.410\n",
      ">2.735\n",
      ">2.285\n",
      ">1.241\n",
      ">1.297\n",
      ">1.484\n",
      ">1.000\n",
      ">1.147\n",
      ">2.149\n",
      ">1.654\n",
      ">1.607\n",
      ">1.635\n",
      ">1.485\n",
      ">1.210\n",
      ">0.960\n",
      ">1.491\n",
      ">1.382\n",
      ">2.586\n",
      ">1.391\n",
      ">1.839\n",
      "MAE: 1.547 (0.414)\n"
     ]
    }
   ],
   "source": [
    "# get the optimized model\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    "\tresults = list()\n",
    "\tn_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\t# define evaluation procedure\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\t# enumerate folds\n",
    "\tfor train_ix, test_ix in cv.split(X):\n",
    "\t\t# prepare data\n",
    "\t\tX_train, X_test = X[train_ix], X[test_ix]\n",
    "\t\ty_train, y_test = y[train_ix], y[test_ix]\n",
    "\t\t# define model\n",
    "\t\tmodel = get_model(n_inputs, n_outputs)\n",
    "\t\t# fit model\n",
    "\t\tmodel.fit(X_train, y_train, verbose=0, epochs=100, batch_size = 20)\n",
    "\t\t# evaluate model on test set\n",
    "\t\tmae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\t\t# store result\n",
    "\t\tprint('>%.3f' % mae)\n",
    "\t\tresults.append(mae)\n",
    "\treturn results\n",
    "\n",
    "# load dataset\n",
    "X, y = get_dataset()\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a912bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e53abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate Deep ANN model \n",
    "def make_regression_ann(Optimizer_trial):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=10, input_dim=7, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=15, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(3, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Optimizer_trial)\n",
    "    return model\n",
    " \n",
    "###########################################\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    " \n",
    "# Listing all the parameters to try\n",
    "Parameter_Trials={'batch_size':[10,20,30],\n",
    "                      'epochs':[10,20],\n",
    "                    'Optimizer_trial':['adam', 'rmsprop']\n",
    "                 }\n",
    " \n",
    "# Creating the regression ANN model\n",
    "RegModel=KerasRegressor(make_regression_ann, verbose=0)\n",
    " \n",
    "###########################################\n",
    "from sklearn.metrics import make_scorer\n",
    " \n",
    "# Defining a custom function to calculate accuracy\n",
    "def Accuracy_Score(orig,pred):\n",
    "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
    "    print('#'*70,'Accuracy:', 100-MAPE)\n",
    "    return(100-MAPE)\n",
    " \n",
    "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
    " \n",
    "#########################################\n",
    "# Creating the Grid search space\n",
    "# See different scoring methods by using sklearn.metrics.SCORERS.keys()\n",
    "grid_search=GridSearchCV(estimator=RegModel, \n",
    "                         param_grid=Parameter_Trials, \n",
    "                         scoring='r2', \n",
    "                         cv=5)\n",
    " \n",
    "#########################################\n",
    "# Measuring how much time it took to find the best params\n",
    "import time\n",
    "StartTime=time.time()\n",
    " \n",
    "# Running Grid Search for different paramenters\n",
    "grid_search.fit(X,y, verbose=1)\n",
    " \n",
    "EndTime=time.time()\n",
    "print(\"########## Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes')\n",
    " \n",
    "print('### Printing Best parameters ###')\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33c19284",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PredictorScalerFit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fitting the ANN to the Training set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train ,batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m Test_Data\u001b[38;5;241m=\u001b[39m\u001b[43mPredictorScalerFit\u001b[49m\u001b[38;5;241m.\u001b[39minverse_transform(X_test)\n\u001b[1;32m      7\u001b[0m TestingData\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mTest_Data, columns\u001b[38;5;241m=\u001b[39mPredictors)\n\u001b[1;32m      8\u001b[0m TestingData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39my_test_orig\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PredictorScalerFit' is not defined"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train ,batch_size = 10, epochs = 20, verbose=0)\n",
    " \n",
    "\n",
    "Test_Data=PredictorScalerFit.inverse_transform(X_test)\n",
    " \n",
    "TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n",
    "TestingData['L']=y_test_orig\n",
    "TestingData['PredictedL']=Predictions\n",
    "TestingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the absolute percent error\n",
    "APE=100*(abs(TestingData['L']-TestingData['PredictedL'])/TestingData['L'])\n",
    "TestingData['APE']=APE\n",
    " \n",
    "print('The Accuracy of ANN model is:', 100-np.mean(APE))\n",
    "TestingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(TestingData['L'], TestingData['PredictedL'], edgecolors=(0, 0, 0))\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], \"k--\", lw=4)\n",
    "ax.set_xlabel(\"Measured\")\n",
    "ax.set_ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5dea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(TestingData['L'], TestingData['APE'], edgecolors=(0, 0, 0))\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], \"k--\", lw=4)\n",
    "ax.set_xlabel(\"Measured\")\n",
    "ax.set_ylabel(\"APE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f62c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, TimeDistributed\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96e8032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression model in Keras\n",
    "def regression_model():\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=20, input_dim=7, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mae', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Use KerasRegressor wrapper (from Keras to sklearn)\n",
    "# The packages we use are meant to be run with sklearn models\n",
    "estimator = KerasRegressor(build_fn=regression_model, validation_split = 0.2, epochs=100, batch_size = 20, verbose=0)\n",
    "history = estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0e51439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history loss\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46c8286d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                7.3834\n",
       "                \n",
       "                    &plusmn; 0.1453\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Lsub\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.95%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                1.0338\n",
       "                \n",
       "                    &plusmn; 0.0570\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                asub\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.6254\n",
       "                \n",
       "                    &plusmn; 0.0402\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bsub\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2229\n",
       "                \n",
       "                    &plusmn; 0.0080\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Lcer\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1467\n",
       "                \n",
       "                    &plusmn; 0.0093\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bcer\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1044\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                acer\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.05%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0945\n",
       "                \n",
       "                    &plusmn; 0.0085\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Thickness\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(estimator, random_state=1).fit(X_train,y_train)\n",
    "eli5.show_weights(perm, feature_names = X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c34acd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=20, input_dim=7, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87694e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get model\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dead839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    "    results = []\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        # define model\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=100, batch_size = 20)\n",
    "        # evaluate model on test set\n",
    "        mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "        # store result\n",
    "        print('>%.3f' % mae)\n",
    "        results.append(mae)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe155bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1.637\n",
      ">1.439\n",
      ">1.483\n",
      ">1.075\n",
      ">1.213\n",
      ">1.344\n",
      ">2.222\n",
      ">1.241\n",
      ">1.175\n",
      ">21.404\n",
      ">1.492\n",
      ">1.217\n",
      ">1.355\n",
      ">2.531\n",
      ">1.234\n",
      ">1.540\n",
      ">1.518\n",
      ">1.663\n",
      ">1.471\n",
      ">2.552\n",
      ">1.060\n",
      ">1.580\n",
      ">21.113\n",
      ">21.314\n",
      ">1.167\n",
      ">1.578\n",
      ">1.390\n",
      ">0.789\n",
      ">1.358\n",
      ">1.504\n",
      "MAE: 3.455 (5.953)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "results = evaluate_model(X, y)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98aeb1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 679us/step\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pred = pd.DataFrame(model.predict(X_test_scaled), columns=['Lpred','apred','bpred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9628f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(Thickness, Lsub, asub, bsub, Lcer, acer, bcer):\n",
    "    list = [Thickness, Lsub, asub, bsub, Lcer, acer, bcer]\n",
    "    df2 = pd.DataFrame(list).T\n",
    "    output = model.predict(df2)\n",
    "    Lf = pd.DataFrame(output, columns = ['L', 'a', 'b'])._get_value(0, 'L')\n",
    "    af = pd.DataFrame(output, columns = ['L', 'a', 'b'])._get_value(0, 'a')\n",
    "    bf = pd.DataFrame(output, columns = ['L', 'a', 'b'])._get_value(0, 'b')\n",
    "    \n",
    "    Lf = np.clip(Lf, np.min([Lcer,Lsub]), np.max([Lcer,Lsub]))\n",
    "    af = np.clip(af, np.min([acer,asub]), np.max([acer,asub]))\n",
    "    bf = np.clip(bf, np.min([bcer,bsub]), np.max([bcer,bsub]))\n",
    "    \n",
    "    return Lf, af, bf\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=[gr.Slider(0, 5, 0.1),\n",
    "                                      gr.Slider(0, 100, 1),\n",
    "                                      gr.Slider(-10, 10, 0.2),\n",
    "                                      gr.Slider(-20, 20, 0.2),\n",
    "                                      gr.Slider(0, 100, 1),\n",
    "                                      gr.Slider(-10, 10, 0.2),\n",
    "                                      gr.Slider(-20, 20, 0.2)], outputs=[\"number\",\"number\", \"number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb2c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
